<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script
      id="MathJax-script"
      async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
    ></script>

    <title>CS 180 NeRF Project</title>
    <style>
      body {
        font-family: "Titillium Web", "HelveticaNeue-Light",
          "Helvetica Neue Light", "Helvetica Neue", Helvetica, "Lucida Grande",
          sans-serif;
        font-weight: 300;
        font-size: 18px;
        margin-left: auto;
        margin-right: auto;
        width: 60%;
        background-color: #f5f5f5;
      }

      h1,
      h2 {
        font-size: 35px;
        font-weight: 300;
        text-align: center;
      }

      h3 {
        font-size: 25px;
        font-weight: 300;
        text-align: center;
        line-height: 30px;
      }

      .code {
        font-size: 18px;
        font-family: "Courier New", Courier, monospace;
        background-color: #f0f0f0;
        padding: 2px 4px;
        border-radius: 3px;
      }

      .equation {
        text-align: center;
        background-color: #f9f9f9;
        padding: 10px;
        margin: 20px 0;
        font-family: "Courier New", Courier, monospace;
      }

      .description {
        margin-bottom: 30px;
        text-align: justify;
      }

      .centered-text {
        text-align: center;
      }

      .comparison-container {
        display: grid;
        grid-template-columns: 1fr 1fr;
        gap: 20px;
        margin-bottom: 30px;
        border-collapse: collapse;
      }

      .comparison-row {
        display: flex;
        flex-direction: column;
        align-items: center;
        text-align: center;
      }

      .comparison-image {
        width: 100%;
        height: auto;
        border: 1px solid #ddd;
        border-radius: 5px;
        margin-bottom: 5px;
      }

      .centered-container {
        text-align: center;
        margin-bottom: 30px;
      }

      .centered-image {
        display: block;
        margin-left: auto;
        margin-right: auto;
        width: 75%;
        height: auto;
        border: 1px solid #ddd;
        border-radius: 5px;
      }

      .image-title,
      .image-description {
        font-size: 16px;
        font-weight: 500;
        color: #333;
        margin: 10px 0;
      }

      .image-grid {
        display: grid;
        grid-template-columns: repeat(3, 1fr);
        grid-gap: 20px;
        margin-bottom: 30px;
      }

      .image-container {
        text-align: center;
      }

      .image-container img {
        width: 100%;
        height: auto;
        border: 1px solid #ddd;
        border-radius: 5px;
      }

      .column-title {
        grid-column: span 1;
        font-size: 30px;
        text-align: center;
        margin-bottom: 10px;
      }

      .table-title {
        grid-column: span 2;
        font-size: 18px;
        font-weight: bold;
        text-align: center;
        margin: 20px 0;
      }

      hr {
        border: 0;
        height: 1px;
        background-image: linear-gradient(
          to right,
          rgba(0, 0, 0, 0),
          rgba(0, 0, 0, 0.75),
          rgba(0, 0, 0, 0)
        );
      }
    </style>
  </head>
  <body>
    <header>
      <h1>CS 180: Neural Radiance Field (NeRF) Project</h1>
    </header>
    <main>
      <section class="description">
        <h2>Project Overview</h2>
        <p>
          This project explores the implementation of Neural Radiance Fields
          (NeRF) to represent 2D images and 3D scenes. The project is divided
          into two parts: fitting a neural field to a 2D image and creating a
          NeRF for multi-view 3D scenes. Techniques like sinusoidal positional
          encoding, ray sampling, and volume rendering are used to build and
          optimize these models.
        </p>
      </section>

      <section class="description">
        <h2>Part 1: Neural Field for 2D Image</h2>
        <p>
          In this part, a neural field is optimized to fit a 2D image. A
          multilayer perceptron (MLP) is used with sinusoidal positional
          encoding to learn the mapping from pixel coordinates to RGB values.
          The training process includes random pixel sampling and minimizing
          mean squared error loss.
        </p>
        <br />
        <p>The hyperparameters we used were:</p>
        <ul>
          <li>Number of layers: 4</li>
          <li>Channel size: 256</li>
          <li>Max frequency for the positional encoding: 10</li>
          <li>Learning rate: 0.01</li>
          <li>Batch Size: 10K</li>
          <li>Number of Epochs: 10</li>
        </ul>

        <div class="centered-container">
          <h3>Training Process Visualization</h3>

          <div class="image-grid">
            <div class="image-container">
              <img src="images/iteration_10.png" alt="iteration_10" />
              <p class="image-title">Iteration 10</p>
            </div>
            <div class="image-container">
              <img src="images/iteration_100.png" alt="iteration_100" />
              <p class="image-title">Iteration 100</p>
            </div>
            <div class="image-container">
              <img src="images/iteration_500.png" alt="iteration_500" />
              <p class="image-title">Iteration 500</p>
            </div>
            <div class="image-container">
              <img src="images/iteration_1000.png" alt="iteration_1000" />
              <p class="image-title">Iteration 1000</p>
            </div>
          </div>
          <p class="image-description">
            Visualization of the predicted image across training iterations.
          </p>
        </div>

        <p>
          Here is the image of the fox with few iterations, many iterations and
          the original image.
        </p>

        <div class="image-grid">
          <div class="image-container">
            <img src="images/animal.jpg" alt="Original Fox" />
            <p class="image-title">Original Fox</p>
          </div>
          <div class="image-container">
            <img
              src="images/animal_reconstructed.png"
              alt="Fox 10 Iterations"
            />
            <p class="image-title">Fox 10 Iterations</p>
          </div>
          <div class="image-container">
            <img src="images/animal_good.png" alt="Fox 1000 Iterations" />
            <p class="image-title">Fox 1000 Iterations</p>
          </div>
        </div>

        <div class="centered-container">
          <h3>PSNR Curve</h3>
          <img
            src="images/psnr_fox.png"
            alt="PSNR Curve for 2D Neural Field"
            class="centered-image"
          />
          <p class="image-description">
            Plot showing the PSNR across training iterations.
          </p>
        </div>

        <div class="image-grid">
          <div class="image-container">
            <img src="images/2d_input_image1.png" alt="Input Image 1" />
            <p class="image-title">Input Image 1</p>
          </div>
          <div class="image-container">
            <img
              src="images/2d_output_image1.png"
              alt="Reconstructed Image 1"
            />
            <p class="image-title">Reconstructed Image 1</p>
          </div>
          <div class="image-container">
            <img
              src="images/2d_output_image2.png"
              alt="Reconstructed Image 2"
            />
            <p class="image-title">Reconstructed Image 2</p>
          </div>
        </div>
      </section>

      <section class="description">
        <h2>Part 2: Neural Radiance Field for 3D Scenes</h2>
        <p>
          This part extends the neural field to 3D scenes using multi-view
          images. Rays are sampled from the images, and a volume rendering
          equation is applied to integrate densities and colors along the rays
          to generate pixel colors. Below is a diagram of the structure for the
          network implemented.
        </p>

        <div class="centered-container">
          <img src="images/structure.png" class="centered-image" />
        </div>

        <div class="centered-container">
          <h3>Camera and Ray Visualization</h3>
          <p>
            Below is the image of how the rays travel from the cameras through
            the images. The points are added to show how the rays sample points
            randomly on the rays and they are perturbed which we can see from
            the fact that the points are not spread out uniformly.
          </p>
          <img
            src="images/nerf_transfer/images/rays_and_samples.png.png"
            alt="Cameras and Rays"
            class="centered-image"
          />
          <p class="image-description">
            Visualization of sampled rays and camera frustums.
          </p>
        </div>

        <div class="centered-container">
          <h3>Volume Rendering Results</h3>
          <p class="image-description">
            Progression of the rendered images during training. The image starts
            out blurry and becomes sharper as the model learns the scene.
          </p>

          <div class="image-grid">
            <div class="image-container">
              <img src="images/e0b500.png" alt="e0b500" />
              <p class="image-title">Epoch 0 Batch 500</p>
            </div>
            <div class="image-container">
              <img src="images/e0b1000.png" alt="e0b1000" />
              <p class="image-title">Epoch 0 Batch 1000</p>
            </div>
            <div class="image-container">
              <img src="images/e1b500.png" alt="e1b500" />
              <p class="image-title">Epoch 1 Batch 500</p>
            </div>
            <div class="image-container">
              <img src="images/e1b1000.png" alt="e1b1000" />
              <p class="image-title">Epoch 1 Batch 1000</p>
            </div>
            <div class="image-container">
              <img src="images/e2b500.png" alt="e2b500" />
              <p class="image-title">Epoch 2 Batch 500</p>
            </div>
            <div class="image-container">
              <img src="images/e2b1000.png" alt="e2b1000" />
              <p class="image-title">Epoch 2 Batch 1000</p>
            </div>
          </div>
        </div>

        <p>
          Here is the video of the final result of the 3D scene from both low
          resolution and high resolution. The high resolution had the following
          hyperparameters:
        </p>
        <ul>
          <li>Number of positional encoding frequencies (L_x): 10</li>
          <li>Number of directional encoding frequencies (L_r_d): 4</li>
          <li>Hidden layer dimension: 256</li>
          <li>RGB output dimension: 3</li>
          <li>Density output dimension: 1</li>
          <li>Number of hidden layers: 8</li>
        </ul>

        <div class="comparison-container">
          <div class="comparison-row">
            <img
              src="images/nerf_render_low.gif"
              alt="Low Resolution"
              class="comparison-image"
            />
            <p class="image-description">Low Resolution</p>
          </div>
          <div class="comparison-row">
            <img
              src="images/nerf_render_high.gif"
              alt="High Resolution"
              class="comparison-image"
            />
            <p class="image-description">High Resolution</p>
          </div>
        </div>

        <div class="centered-container">
          <h3>PSNR Curve</h3>
          <p>
            As we can see from the plot below, the curve is rapidly increasing
            in the begninning and slowly converging to a high PSNR value of
            around 23-24 PSNR. Our final PSNR value was 23.6.
          </p>
          <img
            src="images/psnr_high.png"
            alt="PSNR Curve for 3D Scene"
            class="centered-image"
          />
          <p class="image-description">
            Plot showing the PSNR for validation images during training.
          </p>
        </div>
      </section>

      <section class="description">
        <h2>Bells and Whistles</h2>
        <p>
          For the B&W Portion, we added a blue background to the video by
          changing the volume function. The way we did this was by setting a
          threshold where if the transmittance was below a certain value, we
          would set the color to blue. This however, causes some aliasing issues
          as we can see which could have been fixed by implementing a solution
          where you add a color inverse proporsionally to the transmittance.
          Below is a video of the final result.
        </p>

        <div class="image-container">
          <img
            src="images/custom_background.png"
            alt="Custom Background Rendering"
          />
          <p class="image-title">Custom Background Rendering</p>
        </div>
      </section>

      <section class="description">
        <h2>Acknowledgements</h2>
        <p>
          This project is part of CS 180 at UC Berkeley. Starter code and
          datasets were provided by course staff.
        </p>
      </section>
    </main>
  </body>
</html>
